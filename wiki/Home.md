# WebCrawlerDemo Wiki

Bienvenue sur le wiki du projet **WebCrawlerDemo** ! Ce wiki documente l'Ã©volution du projet Ã  travers diffÃ©rentes itÃ©rations.

## ğŸ“š Contenu

- **[Iterations](Iterations)** - DÃ©tails de chaque itÃ©ration du projet
- **[IA comme AccÃ©lÃ©rateur pour DÃ©veloppeurs Seniors](IA-Accelerateur-Developpeurs-Seniors)** - RÃ©flexion sur l'utilisation de l'IA dans le dÃ©veloppement
- **[Architecture](Architecture)** - Architecture et design patterns utilisÃ©s
- **[API Reference](API-Reference)** - Documentation de l'API

## ğŸ¯ Objectif du Projet

ImplÃ©menter un algorithme de web crawling pour extraire les adresses emails (liens `mailto:`) d'une page web et de ses pages rÃ©fÃ©rencÃ©es, avec contrÃ´le de la profondeur de recherche.

## ğŸ”„ Approche de DÃ©veloppement

Ce projet suit une approche **itÃ©rative et incrÃ©mentale**, oÃ¹ chaque itÃ©ration ajoute une fonctionnalitÃ© ou amÃ©lioration spÃ©cifique :

1. âœ… **ItÃ©ration 1** - Algorithme BFS de base avec HTML/XML valide
2. ğŸš§ **ItÃ©ration 2** - Gestion du HTML rÃ©el (pas uniquement XML valide)
3. ğŸ“‹ **ItÃ©ration 3** - Support des URLs absolues et domaines multiples
4. ğŸ“‹ **ItÃ©ration 4** - Rate limiting et politeness policies
5. ğŸ“‹ **ItÃ©ration 5** - Gestion du robots.txt
6. ğŸ“‹ **ItÃ©ration 6** - Tests unitaires complets
7. ğŸ“‹ **ItÃ©ration 7** - Logging structurÃ©

## ğŸ› ï¸ Technologies

- .NET 8.0
- C# 12
- Algorithme BFS (Breadth-First Search)
- SOLID Principles

## ğŸ“– Navigation

Consultez la page **[Iterations](Iterations)** pour voir les dÃ©tails techniques de chaque Ã©tape du dÃ©veloppement.