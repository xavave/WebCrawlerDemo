# WebCrawlerDemo Wiki

Bienvenue sur le wiki du projet **WebCrawlerDemo** ! Ce wiki documente l'évolution du projet à travers différentes itérations.

## 📚 Contenu

- **[Iterations](Iterations)** - Détails de chaque itération du projet
- **[IA comme Accélérateur pour Développeurs Seniors](IA-Accelerateur-Developpeurs-Seniors)** - Réflexion sur l'utilisation de l'IA dans le développement
- **[Architecture](Architecture)** - Architecture et design patterns utilisés
- **[API Reference](API-Reference)** - Documentation de l'API

## 🎯 Objectif du Projet

Implémenter un algorithme de web crawling pour extraire les adresses emails (liens `mailto:`) d'une page web et de ses pages référencées, avec contrôle de la profondeur de recherche.

## 🔄 Approche de Développement

Ce projet suit une approche **itérative et incrémentale**, où chaque itération ajoute une fonctionnalité ou amélioration spécifique :

1. ✅ **Itération 1** - Algorithme BFS de base avec HTML/XML valide
2. 🚧 **Itération 2** - Gestion du HTML réel (pas uniquement XML valide)
3. 📋 **Itération 3** - Support des URLs absolues et domaines multiples
4. 📋 **Itération 4** - Rate limiting et politeness policies
5. 📋 **Itération 5** - Gestion du robots.txt
6. 📋 **Itération 6** - Tests unitaires complets
7. 📋 **Itération 7** - Logging structuré

## 🛠️ Technologies

- .NET 8.0
- C# 12
- Algorithme BFS (Breadth-First Search)
- SOLID Principles

## 📖 Navigation

Consultez la page **[Iterations](Iterations)** pour voir les détails techniques de chaque étape du développement.